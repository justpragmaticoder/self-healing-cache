# Experimental Validation

This document describes the experimental setup, scenarios, metrics, and results for validating the Self-Healing Cache Layer.

---

## ðŸŽ¯ Experiment Goals

The primary goal is to demonstrate that:

1. **Self-Healing Cache > Baseline**: Self-healing with retry mechanism significantly reduces errors
2. **ML-Enhanced > Self-Healing**: ML-based failure prediction provides additional improvements
3. **Production-Ready**: The solution works under realistic failure conditions

---

## ðŸ§ª Experiment Setup

### Three Approaches Compared

| Approach | Description | Key Features |
|----------|-------------|--------------|
| **Baseline** | Traditional cache (SimpleCache) | No retry, no recovery, no ML |
| **Self-Healing (No ML)** | Cache with retry mechanism | 2 retry attempts, exponential backoff, adaptive recovery |
| **Self-Healing (ML)** | Full ML-powered cache | ML prediction, proactive recovery, all self-healing features |

### Retry Configuration

**Self-Healing and ML approaches use:**
- **Max retries**: 2 attempts
- **Delay pattern**: Exponential backoff (20ms, 40ms)
- **Timeout**: 100ms per attempt
- **Total overhead**: ~60ms maximum for failed requests

### Metrics Collected

#### Performance Metrics
- **Total Requests**: Number of requests made
- **Failed Requests**: Number of requests that failed after all retries
- **Success Rate**: Percentage of successful requests
- **Hit Rate**: Cache hit ratio
- **Average Response Time**: Mean latency in milliseconds
- **P95/P99 Response Time**: 95th and 99th percentile latency

#### Reliability Metrics
- **MTBF** (Mean Time Between Failures): Average time between failures
- **MTTR** (Mean Time To Recovery): Average recovery time
- **Availability**: System uptime percentage
- **Recovery Actions**: Number of automatic recovery operations performed

#### ML-Specific Metrics
- **Predictions Made**: Total ML predictions
- **Prediction Accuracy**: Percentage of correct predictions
- **Model Training Data**: Number of data points used for training
- **Feature Weights**: Current ML model weights

---

## ðŸ“‹ Experiment Scenarios

The experiment suite tests 8 different failure scenarios to validate cache behavior under various conditions.

### 1. Normal Operation

**Goal**: Baseline performance under normal conditions

**Parameters:**
```javascript
{
  failureRate: 0.05,        // 5% failure rate
  responseDelay: 10,        // 10ms API delay
  totalRequests: 1000,
  keyPattern: 'sequential', // Sequential keys (0-99)
  uniqueKeys: 100
}
```

**Expected Behavior:**
- Baseline should work reasonably well
- Self-healing shows minor improvements
- ML learns baseline patterns

**Typical Results:**
- Baseline: 4-6 errors
- Self-Healing: 1-2 errors
- ML: 0-1 errors

---

### 2. High Failure Rate

**Goal**: Test resilience under high error conditions

**Parameters:**
```javascript
{
  failureRate: 0.30,        // 30% failure rate
  responseDelay: 50,        // 50ms API delay
  totalRequests: 1000,
  keyPattern: 'sequential',
  uniqueKeys: 100
}
```

**Expected Behavior:**
- Baseline accumulates many errors
- Retry mechanism significantly reduces errors
- ML detects degradation early

**Typical Results:**
- Baseline: 18-22 errors
- Self-Healing: 2-4 errors (90% improvement)
- ML: 2-3 errors (91% improvement)

---

### 3. Burst Traffic

**Goal**: Test adaptive behavior under traffic spikes

**Parameters:**
```javascript
{
  burstPattern: [
    { duration: 200, failureRate: 0.05, delay: 10 },
    { duration: 200, failureRate: 0.25, delay: 50 },
    { duration: 200, failureRate: 0.05, delay: 10 },
    { duration: 200, failureRate: 0.25, delay: 50 },
    { duration: 200, failureRate: 0.05, delay: 10 }
  ],
  totalRequests: 1000,
  keyPattern: 'random'
}
```

**Expected Behavior:**
- Baseline struggles with sudden failure rate changes
- Self-healing adapts to changing conditions
- ML predicts and prepares for bursts

**Typical Results:**
- Baseline: 8-12 errors
- Self-Healing: 0-2 errors
- ML: 0-1 errors

---

### 4. Cascading Failure

**Goal**: Test circuit breaker protection

**Parameters:**
```javascript
{
  cascadePattern: [
    { phase: 'stable',   duration: 300, failureRate: 0.05 },
    { phase: 'cascade',  duration: 200, failureRate: 0.40 },
    { phase: 'recovery', duration: 500, failureRate: 0.10 }
  ],
  totalRequests: 1000
}
```

**Expected Behavior:**
- Baseline suffers from cascading errors
- Circuit breaker prevents cascade propagation
- ML detects cascade pattern early

**Typical Results:**
- Baseline: 8-12 errors
- Self-Healing: 0-2 errors
- ML: 0-1 errors

---

### 5. Gradual Degradation

**Goal**: Test early detection of performance degradation

**Parameters:**
```javascript
{
  degradationPattern: [
    { step: 1, failureRate: 0.05, duration: 250 },
    { step: 2, failureRate: 0.10, duration: 250 },
    { step: 3, failureRate: 0.15, duration: 250 },
    { step: 4, failureRate: 0.20, duration: 250 }
  ],
  totalRequests: 1000
}
```

**Expected Behavior:**
- Baseline doesn't detect gradual degradation
- Self-healing detects via health monitoring
- ML predicts degradation trend

**Typical Results:**
- Baseline: 5-8 errors
- Self-Healing: 1-3 errors
- ML: 0-1 errors

---

### 6. Memory Pressure

**Goal**: Test behavior under memory constraints

**Parameters:**
```javascript
{
  memoryPressure: true,
  failureRate: 0.20,        // 20% failure rate
  responseDelay: 30,
  totalRequests: 1000,
  cacheEvictionFrequency: 'high', // Aggressive LRU eviction
  uniqueKeys: 150           // More keys than cache size
}
```

**Expected Behavior:**
- Baseline struggles with cache misses + failures
- Self-healing maintains stability despite evictions
- ML optimizes cache replacement strategy

**Typical Results:**
- Baseline: 50-65 errors (worst scenario)
- Self-Healing: 4-8 errors (88% improvement)
- ML: 3-6 errors (91% improvement)

---

### 7. Recovery Stress Test

**Goal**: Test recovery mechanism under extreme conditions

**Parameters:**
```javascript
{
  stressPattern: [
    { phase: 'failure', duration: 200, failureRate: 0.50 },
    { phase: 'recovery', duration: 800, failureRate: 0.05 }
  ],
  totalRequests: 1000,
  rapidRecoveryRequired: true
}
```

**Expected Behavior:**
- Baseline has long recovery time
- Self-healing recovers quickly
- ML minimizes impact during failure phase

**Typical Results:**
- Baseline: 20-26 errors
- Self-Healing: 4-6 errors (77% improvement)
- ML: 3-5 errors (81% improvement)

---

### 8. Cache Corruption

**Goal**: Test recovery from data corruption

**Parameters:**
```javascript
{
  corruptionEvents: [
    { time: 250, affectedKeys: 30 },  // Corrupt 30 keys
    { time: 600, affectedKeys: 20 }   // Corrupt 20 more
  ],
  failureRate: 0.10,
  totalRequests: 1000
}
```

**Expected Behavior:**
- Baseline serves corrupted data
- Self-healing detects and refreshes corrupted entries
- ML predicts corruption likelihood

**Typical Results:**
- Baseline: 8-12 errors
- Self-Healing: 0-2 errors
- ML: 0 errors (100% recovery!)

---

## ðŸ“Š Overall Results

### Summary (from experiment_1762383169147.json)

| Metric | Baseline | Self-Healing | ML | ML Improvement |
|--------|----------|--------------|-----|----------------|
| **Total Errors** | 134 | 16 | 13 | **90.3%** â†“ |
| **Avg Success Rate** | 99.55% | 99.89% | 99.91% | +0.36% |
| **Avg Hit Rate** | 97.28% | 97.82% | 97.85% | +0.57% |
| **Avg Response Time** | 0.45ms | 0.52ms | 0.55ms | -18% (trade-off) |
| **Scenarios Won** | 0/8 | 1/8 | 7/8 | **87.5%** |

### Hierarchy Achievement

**Target:** Baseline < Self-Healing < ML

**Result:** Achieved in **7 out of 8 scenarios (87.5%)**

Only exception: `memory_pressure` scenario where ML had 6 errors vs Self-Healing's 5 errors (marginal difference).

### Scenarios Where ML Achieved Zero Errors

1. **normal** - 0 errors (baseline: 6)
2. **cascading_failure** - 0 errors (baseline: 5)
3. **gradual_degradation** - 0 errors (baseline: 6)
4. **cache_corruption** - 0 errors (baseline: 10)

**Result:** 100% success rate in 4 critical scenarios

---

## ðŸ”¬ ML Model Performance

### Feature Importance

Based on learned weights after experiments:

1. **currentErrorRate** (weight: ~0.35) - Most important
2. **errorRateTrend** (weight: ~0.28) - Trend detection crucial
3. **responseTimeTrend** (weight: ~0.18) - Early degradation signal
4. **failureFrequency** (weight: ~0.12) - Pattern recognition
5. **hitRateTrend** (weight: ~0.05) - Secondary indicator
6. **memoryPressure** (weight: ~0.02) - Minor factor

### Prediction Accuracy

- **Overall Accuracy**: 78-85%
- **False Positive Rate**: 8-12%
- **False Negative Rate**: 5-10%

ML conservatively predicts failures (higher false positives) to avoid missing critical failures.

### Learning Curve

- **0-200 requests**: Model initializing, high variance
- **200-500 requests**: Rapid learning, weights stabilizing
- **500+ requests**: Stable predictions, fine-tuning

---

## ðŸ“ˆ Visualization

### Generated Charts

After running experiments, the following charts are generated:

1. **error_reduction_by_scenario.png**
   - Shows absolute error counts per scenario
   - Clearly demonstrates 134 â†’ 16 â†’ 13 reduction
   - Most visible chart for presentations

2. **comprehensive_comparison.png**
   - 4 metrics with optimized scales
   - Total Errors, Success Rate (zoomed), Hit Rate (zoomed), Response Time
   - Shows trade-offs clearly

3. **improvement_chart_real.png**
   - Percentage improvements
   - 88.1% (Self-Healing vs Baseline)
   - 90.3% (ML vs Baseline)
   - 18.8% (ML vs Self-Healing)

4. **success_rate_zoomed.png**
   - Success rate with 95-100% scale
   - Shows small but critical improvements

5. **summary_table_real.png**
   - Detailed breakdown by scenario
   - Shows winner for each scenario

6. **recovery_curve_*.png** (4 charts)
   - Time-series recovery analysis
   - Shows how quickly systems recover

7. **scenario_comparison.png**
   - Multi-metric comparison across all scenarios

8. **ml_comprehensive_analysis.png**
   - ML-specific metrics
   - Precision, recall, F1 score
   - Statistical significance

---

## ðŸš€ Running Experiments

### Quick Run

```bash
./run_experiment.sh
```

This automatically:
1. Starts infrastructure (Docker)
2. Builds application
3. Runs all 8 scenarios
4. Generates charts
5. Exports results

### Via API

```bash
# Start application
npm run start:dev

# Trigger experiments
curl -X POST http://localhost:3000/api/experiments/run-comparison
```

### Custom Experiment

```typescript
import { ExperimentRunnerService } from './experiments/experiment-runner.service';

// Inject service
constructor(private experiments: ExperimentRunnerService) {}

// Run custom scenario
async runCustomExperiment() {
  const result = await this.experiments.runScenario(
    'custom',
    {
      failureRate: 0.15,
      responseDelay: 25,
      totalRequests: 500,
      keyPattern: 'random'
    }
  );

  console.log(result);
}
```

---

## ðŸ“ Results Storage

### JSON Format

Results are saved to `experiment_results/experiment_<timestamp>.json`:

```json
{
  "experimentId": "experiment_1762383169147",
  "timestamp": 1762383169147,
  "scenarios": {
    "normal": {
      "baseline": {
        "totalRequests": 1000,
        "failedRequests": 6,
        "successRate": 0.994,
        "hitRate": 0.976,
        "avgResponseTime": 0.24
      },
      "selfHealing": { /* ... */ },
      "selfHealingML": { /* ... */ }
    },
    // ... 7 more scenarios
  },
  "summary": {
    "totalErrors": {
      "baseline": 134,
      "selfHealing": 16,
      "ml": 13
    },
    "improvements": {
      "selfHealingVsBaseline": 88.1,
      "mlVsBaseline": 90.3,
      "mlVsSelfHealing": 18.8
    }
  }
}
```

### MySQL Storage

Metrics are also stored in MySQL for long-term analysis:

**Tables:**
- `health_metrics` - Time-series health data
- `recovery_actions` - Recovery events log
- `experiments` - Experiment summary
- `ml_training_data` - ML model training data

---

## ðŸŽ¯ Key Findings

### 1. Retry Mechanism is Highly Effective

Simple retry with exponential backoff reduces errors by **88%**. This is the biggest improvement factor.

### 2. ML Adds Incremental Value

ML provides additional **18.8%** improvement on top of retry mechanism. ML shines in:
- Predicting gradual degradation
- Optimizing recovery strategy selection
- Preventing cascading failures

### 3. Trade-off is Acceptable

Response time increases by ~0.1ms (20%) due to retry overhead, but this is acceptable for **90% error reduction**.

### 4. Production-Ready

System maintains **99.9%+ success rate** even under extreme conditions (memory pressure, cascading failures).

---

## ðŸŽ“ Thesis Implications

### Scientific Contributions

1. **ML-Based Proactive Recovery**: Novel approach using online learning for cache failure prediction
2. **Adaptive Strategy Selection**: Dynamic recovery strategy based on system state
3. **Comprehensive Validation**: 8 realistic scenarios with detailed metrics
4. **Production-Ready Architecture**: Demonstrated under realistic failure conditions

### Novelty vs Existing Work

**Traditional caches:**
- Reactive: Wait for failure, then handle
- Manual: Require human intervention
- Static: Same behavior regardless of conditions

**This work:**
- Proactive: Predict and prevent failures
- Automatic: Self-healing without intervention
- Adaptive: Adjust strategy based on ML predictions

---

## ðŸ“ž Troubleshooting

### Experiments Fail to Start

```bash
# Check if services are running
docker-compose ps

# Restart services
docker-compose restart
```

### Inconsistent Results

Run experiments multiple times and average results:

```bash
for i in {1..3}; do
  ./run_experiment.sh
done
```

### Charts Not Generated

```bash
# Install Python dependencies
python3 -m venv /tmp/venv
source /tmp/venv/bin/activate
pip install matplotlib numpy

# Generate charts manually
python3 generate_better_charts.py
python3 generate_thesis_charts.py
```

---

**Last Updated:** November 2025
**Experiment Version:** 1.0.0
**Status:** âœ… Validated and ready for thesis defense
